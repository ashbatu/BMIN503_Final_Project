---
title: "Evaluating EHR Data Sources and Provider Contexts for Predicting Clinical Trial Exclusions in Obstructive Sleep Apnea (OSA) Screening"
subtitle: "BMIN503/EPID600 Final Project"
author: "Ashley Batugo"
format: html
editor: visual
number-sections: true
embed-resources: true
---

------------------------------------------------------------------------

## Overview {#sec-overview}

This project examined which combinations of EHR data sources, provider specialties, and temporal windows most effectively predicted exclusion criteria during Obstructive Sleep Apnea (OSA) trial screening. Using manually chart-reviewed exclusion cases from during 2025 trial recruitment, I constructed an evidence-level analytical data set integrating note-level and structured EHR features and applied logistic regression with Synthetic Minority Oversampling Technique (SMOTE) to address class imbalance. Discussions with Dr. Danielle Mowery and Emily Schriver helped shape the dataset design and modeling strategy for working with a small sample. The materials for this project can be found in this [Github repository](https://github.com/ashbatu/BMIN503_Final_Project).

## Introduction {#sec-introduction}

Clinical research is essential for advancing medical knowledge, particularly for conditions that are often underrecognized and underdiagnosed, such as OSA ([Motamedi et al., 2009](https://pmc.ncbi.nlm.nih.gov/articles/PMC3096276/)). Successful clinical trials depend on many factors including strong study design, careful planning, timely recruitment, and sustained participation retention ([Lai et al., 2019](https://journals.sagepub.com/doi/full/10.1177/1740774519829709?casa_token=mm71iIUcfGkAAAAA%3AvRwJV3xTHnNLQ2-WsNICmuzN-IQLbLRioaR-lmo3lrqEWKBfZ-WFaB21-bRNLq34dCeeWsCGKWi9Yg)). However, identifying eligible patients remains one of the major challenges in clinical research ([Cai et al., 2021](https://acrjournals.onlinelibrary.wiley.com/doi/10.1002/acr2.11289#:~:text=The%20LiiRA%20study%20team%20incorporated,not%20screening%20out%20eligible%20patients.)). With the widespread use of electronic health records (EHRs), researchers increasingly rely on EHR data to assist with recruitment. Yet the process of manually reviewing charts to determine patient eligibility and exclusion status is complex, requires clinical expertise, and can take hours each day, which slows recruitment and add significant burden to study teams ([Etchberger, 2016](https://www.linkedin.com/pulse/chart-review-should-sponsors-pay-clinical-research-sites-etchberger#:~:text=Some%20trials%20remain%20very%20complicated,takes%20to%20find%20those%20patients.)). These challenges are particularly critical for milestone-driven NIH-funded projects, where delays in meeting recruitment goals can jeopardize continued funding. This project was motivated by an ongoing NIH-funded OSA clinical trial I am part of, where our team has faced recruitment delays due to how resource intensive the chart review process is for our clinical research coordinators.

Addressing this problem requires collaboration with experts from different fields including medicine, informatics, and clinical research operations. Clinicians provide the judgement needed to determine which patients should be included or excluded, assist with recruitment within their own patient populations, and interpret the context of the notes and patient charts. Informatics and data science contribute the methods to extract, organize, and analyze EHR data to identify patients who may meet or fail eligibility criteria. Additionally, this problem is directly tied to clinical research operations, since improving recruitment directly benefits those responsible for identifying, reaching out, and enrolling participants. In developing this project, conversations with Dr. Danielle Mowery, Director of the Institute for Biomedical Informatics (CIC), and Emily Schriver, a translational data scientist in the CIC, helped clarify how informatics can be applied to identify meaningful EHR features that support clinical teams in improving recruitment workflows.

## Methods {#sec-methods}

Describe the data used and general methodological approach used to address the problem described in the @sec-introduction. Subsequently, incorporate full R code necessary to retrieve and clean data, and perform analysis. Be sure to include a description of code so that others (including your future self) can understand what you are doing and why.

## Results {#sec-results}

Describe your results and include relevant tables, plots, and code/comments used to obtain them. You may refer to the @sec-methods as needed. End with a brief conclusion of your findings related to the question you set out to address. You can include references if you'd like, but this is not required.

## Conclusion

This the conclusion. The @sec-results can be invoked here.
